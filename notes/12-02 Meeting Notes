Note: Datasets are essentially Samples. They represent single or paired-end fastqs from a particular Illumina library. 



Questions To Review: 


Dataset-based attributes like these will enable auto-configuration of parameters when launching analysis, simplifying and making more uniform our analyses: 
		species
		chain [HEAVY, LIGHT, TCRA, TCRB]
		locus [IgH, IgL, IgK, TRA, TRB]


Dataset attributes will also make sample comparisons much easier. Can import these from existing experiment collection
		cell sorting markers 
		primer specificities 
		cell types 
		isotypes 
		polymerases / methodologies 
		Library preparer 
		adjuvant 



	What about chain/loci designation for VH::VL paired data fastqs? 
		--Will include 'VH::VL' ambiguous in chain options so all IgH,IgK,IgL loci will be in alignment reference 
		--Data will be paired so it might be attractive to just assign one HEAVY and one LIGHT, but if we run R1/R2 alignments separately this wouldn't work 




Parsing GSAF JSON Output File, Which Can Include Multiple Samples If MID-Barcoded Library Is Run 
	When will this file be available? 
		--When sequence data becomes available 
		++Costas is getting code to download pack of files from particular job/sequencing submission, including json 


		Path in output refers to biotseq local path? Thought it would be S3 url...: 
		{u'path': u'scratch/results/job-44207/memTCR-C_S3_L001_R1_001.fastq.gz'}
		Perhaps Zack's file download code also modifies this? 


	Create Experiment + Datasets On File Parsing?
		-- We'll demultiplex fastq into dataset(sample)-specific fastqs on import 




Things To Think About 

Sharing fastq files (through symlinks so zero additional data bulk) instead of storing large raw sequence data in the db. Would need to deletion-protect shared files? 









